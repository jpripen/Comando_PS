{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic Project\n",
    "## by Comando PS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Table of contents\n",
    "\n",
    "1. Table of Contents  \n",
    "2. [Introduction](#Introduction)  \n",
    "3. [Business Understanding](#Business_understanding)  \n",
    "    3.1. [Background](#Background)  \n",
    "    3.2. [Problem description](#Problem_description)  \n",
    "    3.3. [Target audience](#Target_audience)  \n",
    "    3.4. [Success criteria](#Success_criteria)  \n",
    "4. [Data Understanding](#Data_understanding)  \n",
    "    4.1. [Structure of training and test sets](#Data_structure)  \n",
    "    4.2. [Submission set](#Submission_set)  \n",
    "    4.3. [Exploratory data analysis](#EDA)  \n",
    "        4.3.1. Survival  \n",
    "        4.3.2. Sex  \n",
    "        4.3.3. Passenger class  \n",
    "        4.3.4. Age  \n",
    "5. [Data preparation](#Data_preparation)  \n",
    "    5.1. [Feature engineering](#Feature_engineering)  \n",
    "        5.1.1. data  \n",
    "        5.1.2. data\n",
    "        5.1.3. data\n",
    "        5.1.4. data\n",
    "    5.2 [Data wrangling](#Data_wrangling)\n",
    "6. [Modeling](#Modeling)  \n",
    "7. [Evaluation](#Evaluation)\n",
    "8. [Conclusion](#Conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "<a id='Introduction'></a>\n",
    "## 2. Introduction\n",
    "\n",
    "In this notebook we will try to complete the introductory project for kaggle, which is trying to predict if a group of passengers on board of RMS Titanic survived or not the [tragic sinking of the ship in the early hours of 15 April 1912](https://en.wikipedia.org/wiki/Sinking_of_the_RMS_Titanic). This notebook is intended to start learning ML so it will be based on some notebooks we have deemed interesting on the internet. References will be provided when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RMS Titanic][RMS]\n",
    "\n",
    "[RMS]: https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/RMS_Titanic_sea_trials_April_2%2C_1912.jpg/637px-RMS_Titanic_sea_trials_April_2%2C_1912.jpg \"RMS Titanic\"\n",
    "\n",
    "To collect insights from data we will be applying the [CRISP-DM](https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining \"Wikipedia CRISP-DM page\") (Cross Industry Standard Process for Data Mining) methodology.\n",
    "\n",
    "![CRISP-DM][MET]\n",
    "\n",
    "[MET]: https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/599px-CRISP-DM_Process_Diagram.png \"CRISP-DM Methodology\"\n",
    "\n",
    "CRISP-DM methodology breaks the process of data mining into six phases:\n",
    "\n",
    "1. Business understanding: Understand what we need from the data.\n",
    "2. Data understanding: See how is the data formatted, what tools we need to operate with it and extract some basic insights (Exploratory Data Analysis, or EDA).\n",
    "3. Data preparation: Data wrangling and feature engineering.\n",
    "4. Modeling: Build a model to extract the answers needed from our data.\n",
    "5. Evaluation: Use a metric to compare our results and gain some feedback from our model to further improve it.\n",
    "6. Deployment: Submit our result to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Business_understanding'></a>\n",
    "## 3. Business understanding\n",
    "\n",
    "<a id='Background'></a>\n",
    "### 3.1. Background\n",
    "\n",
    "The sinking of RMS Titanic is one of the most infamous sinkings in contemporary history. The RMS Titanic sank in the early hours of 15 April 1912, four days into her maiden's voyage after she struck an iceberg. Of the 2224 estimated people on board approximately 1500 people died in the accident, making it one of the most lethal peacetime maritimal disasters in history.\n",
    "\n",
    "One of the reasons for such lethality was that there was not enough lifeboats for everyone. There was some element of luck involved in the survival probability, but there is evidence that some groups of people were more fortunate than others.\n",
    "\n",
    "<a id='Problem_description'></a>\n",
    "### 3.2. Problem description\n",
    "\n",
    "Using some data from the RMS Titanic passenger list we have to predict whether or not a given passenger had survived the sinking or not. Kaggle is asking us to build a predictive model answering the following question: “what sorts of people were more likely to survive? using passenger data (ie name, age, gender, socio-economic class, etc)\". \n",
    "\n",
    "<a id='Target_audience'></a>\n",
    "### 3.3. Target audience\n",
    "\n",
    "This notebook will be used to learn some machine learning techniques and how to manage a successful team. The primary audience will be ourselves, but when it is finished it will be published for anyone to read. Any constructive criticism will be welcome.\n",
    "\n",
    "<a id='Success_criteria'></a>\n",
    "### 3.4. Success criteria\n",
    "\n",
    "The main metric employed to decide our model is successful or not is the accuracy of the model (i.e. in how many passengers the outcome was correctly predicted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data_understanding'></a>\n",
    "## 4. Data understanding\n",
    "\n",
    "Kaggle gives us two different csv files. One will be used to train our model (called train.csv) whereas the other will be used to test the model (unsurprisingly called test.csv). Test.csv does not contain information about the survival outcome of the passenger and we need to infer it from our model.\n",
    "\n",
    "<a id='Data_structure'></a>\n",
    "### 4.1. Structure of training and test sets\n",
    "\n",
    "Train.csv contains data from 891 different passengers of the titanic with unique ID and full name, stating if they survived or not (column 'survived'), the ticket class ('Pclass'), sex ('Sex'), number of siblings/spouses aboard ('Sibsp'), number of parents/children aboard ('parch'), ticket number ('ticket'), fare ('fare'), cabin number aboard ('cabin') and port of embarcation ('embarked').\n",
    "\n",
    "Some notes from the documentation:\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "<a id='Submission_set'></a>\n",
    "### 4.2. Submission set\n",
    "\n",
    "The submission set shall be composed of only two columns: The passenger id from the test set and a column indicating if that passenger survived or not.\n",
    "\n",
    "<a id='EDA'></a>\n",
    "### 4.3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "First, some libraries will be imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #pandas is a data analysis and manipulation tool.\n",
    "import numpy as np #Package for scientific computing with Python.\n",
    "import matplotlib.pyplot as plt #Python data visualization library.\n",
    "import seaborn as sns #Python data visualization library based on matplotlib.\n",
    "import re #regular expressions\n",
    "\n",
    "#Matlplotlib and seaborn options:\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study the full set, let's merge both datasets. In the case of the test data, the survival value will be set to NaN. The passenger ID is a unique number, different for every passenger on board. This ID will be set as the index of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: \n",
      " df_train:  (891, 12) \n",
      " df_test:   (418, 12) \n",
      " df_full:   (1309, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                 0.0       3   \n",
       "2                 1.0       1   \n",
       "3                 1.0       3   \n",
       "4                 1.0       1   \n",
       "5                 0.0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.read_csv('data/train.csv')\n",
    "df_test=pd.read_csv('data/test.csv')\n",
    "\n",
    "survive=np.empty((418,1))\n",
    "survive[:]=np.nan\n",
    "df_test.insert(1,'Survived',survive)\n",
    "\n",
    "df_full=df_train.append(df_test,ignore_index=True)\n",
    "print('Dataset sizes:','\\n df_train: ',df_train.shape,'\\n df_test:  ',df_test.shape,'\\n df_full:  ',df_full.shape)\n",
    "\n",
    "df_full.reset_index()\n",
    "df_full.set_index('PassengerId', inplace=True) #Set the passenger id as index in both the test and train sets\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type for each column is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    float64\n",
       "Pclass        int64\n",
       "Name         object\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Ticket       object\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset there are both numerical variables (survived, pclass...) and categorical variables (sex, embarked). Categorical variables will be transformed to something the models can use using dummy variables. This means that the categorical variables will be transformed into dichotomic categorical variables in form of a number (1 for yes, 0 for no). This will be performed before the modeling section.\n",
    "\n",
    "Since survived is either 1 or 0, it will be transformed into an integer type (int64), as is Pclass. Name is comprised of different strings, as the Sex column, but that one will be transformed. Age is float, since there are some estimation in the ages and those are indicated with a \".5\". SibSp and Parch are people counts, so they are integers. Ticket is another string. Fare is a floating point number with sometimes a lot of decimals. This is due to the fact that the currency used in 1912 in the United Kingdom did not follow base-10 numbers. More information can be found in the [pre-decimal currency Wikipedia article](https://en.wikipedia.org/wiki/%C2%A3sd). Cabin is another string, and, finally, Embarked is a categorical variable with each letter indicating where the passenger boarded the ship.\n",
    "\n",
    "In the next cell, a brief statistical description of both categorical and numerical variables can be seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309</td>\n",
       "      <td>1309</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309</td>\n",
       "      <td>1308.000000</td>\n",
       "      <td>295</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1307</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.295479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.758668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived       Pclass                  Name   Sex          Age  \\\n",
       "count   891.000000  1309.000000                  1309  1309  1046.000000   \n",
       "unique         NaN          NaN                  1307     2          NaN   \n",
       "top            NaN          NaN  Connolly, Miss. Kate  male          NaN   \n",
       "freq           NaN          NaN                     2   843          NaN   \n",
       "mean      0.383838     2.294882                   NaN   NaN    29.881138   \n",
       "std       0.486592     0.837836                   NaN   NaN    14.413493   \n",
       "min       0.000000     1.000000                   NaN   NaN     0.170000   \n",
       "25%       0.000000     2.000000                   NaN   NaN    21.000000   \n",
       "50%       0.000000     3.000000                   NaN   NaN    28.000000   \n",
       "75%       1.000000     3.000000                   NaN   NaN    39.000000   \n",
       "max       1.000000     3.000000                   NaN   NaN    80.000000   \n",
       "\n",
       "              SibSp        Parch    Ticket         Fare        Cabin Embarked  \n",
       "count   1309.000000  1309.000000      1309  1308.000000          295     1307  \n",
       "unique          NaN          NaN       929          NaN          186        3  \n",
       "top             NaN          NaN  CA. 2343          NaN  C23 C25 C27        S  \n",
       "freq            NaN          NaN        11          NaN            6      914  \n",
       "mean       0.498854     0.385027       NaN    33.295479          NaN      NaN  \n",
       "std        1.041658     0.865560       NaN    51.758668          NaN      NaN  \n",
       "min        0.000000     0.000000       NaN     0.000000          NaN      NaN  \n",
       "25%        0.000000     0.000000       NaN     7.895800          NaN      NaN  \n",
       "50%        0.000000     0.000000       NaN    14.454200          NaN      NaN  \n",
       "75%        1.000000     0.000000       NaN    31.275000          NaN      NaN  \n",
       "max        8.000000     9.000000       NaN   512.329200          NaN      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1. Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean       0.383838\n",
       "std        0.486592\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['Survived'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for the survival outcome of the passengers is only known for the passengers in the training set (891 out of 1309 people). Only the 38% of passengers in the set have survived the sinking. In the following sections we will explore how survival correlates with other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of females: 466\n",
      "Number of males: 843\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of females:\", df_full.loc[df_full.Sex=='female'].shape[0])\n",
    "print(\"Number of males:\", df_full.loc[df_full.Sex=='male'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 466 females and 843 males in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the kaggle tutorial it is explained that gender played a key role in regards of survival probability, even creating a model that only looked at the sex of the passenger and then assigning the label survived=1 to females only, obtaining an impressive punctuation in the leaderboard. Let us explore how sex correlates with survival probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of women who survived: 74.2 %\n",
      "Percentage of men who survived: 18.89 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rate_women=100 * df_train.loc[df_train.Sex == 'female'][\"Survived\"].sum()/df_train.loc[df_train.Sex=='female'].shape[0]\n",
    "rate_men=100 * df_train.loc[df_train.Sex == 'male'][\"Survived\"].sum()/df_train.loc[df_train.Sex=='male'].shape[0]\n",
    "\n",
    "print(\"Percentage of women who survived:\", round(rate_women,2),'%')\n",
    "print(\"Percentage of men who survived:\", round(rate_men,2),'%')\n",
    "\n",
    "fig1=sns.barplot(x=\"Sex\", y=\"Survived\", data=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 18.89 % of men survived, compared with the 74.2 % of women. Is it true the \"Women and children first\" saying? Apparently, in 1912 it was _en vogue_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3. Passenger class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2=sns.barplot(x=\"Pclass\", y=\"Survived\", data=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People in first class have more survival rate, than the other two ticket classes. It is possible that the social class can be used as a feature of our survival prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig3=sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ther are 1046 values of 1309 possible values. This indicates that some age values are missing. The average age is less than 30 years old (29.9 years), with a standard deviation of 14.4 years. The youngest recorded passenger was a little older than 2 months (0.17 years) old, whereas the oldest passenger was 80 years old. More than 75% of the passengers were less than 40 years old. How are the age and the survival outcome correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ages=pd.DataFrame()\n",
    "#df_ages['Age']=pd.cut(df_train['Age'], 8)\n",
    "#df_ages['Survived']=df_train['Survived']\n",
    "#df_ages[['Age', 'Survived']].groupby(['Age'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "labels=['Survived','Not survived']\n",
    "for a,lab in zip([df_full[df_full['Survived']==1]['Age'], df_full[df_full['Survived']==0]['Age']],labels):\n",
    "    sns.distplot(a, bins=range(0, 81, 10), ax=ax2, kde=False, label=lab)\n",
    "ax.set_xlim([0, 80])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows us how the survival probability correlates with age. We can see that is more probable to survive for people from 0 to 10 years old. In the other groups of age it is more probable to not survive than leaving the sinking boat alive. This is specially significant in the 20-40 year brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about we combine both sex and age and study the survival probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1=sns.FacetGrid(df_full,hue='Survived',aspect=4,row='Sex')\n",
    "fig1.map(sns.kdeplot,'Age',shade=True)\n",
    "fig1.set(xlim=(0,df_full[\"Age\"].max()))\n",
    "fig1.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Survived',y='Age',hue='Sex',data=df_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For both sexes, the bulk of people surviving concentrates in the ages between 20 and 40 years old. There is a local maximum for young males. The survival distribution for females tends to be more uniform, with females surviving around all age brackets and showing a maximum at around 25 years of age. There is also a little peak at around 50 years old that is not shown for the male population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ticket Fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the following graph we can see the survival probability as a function of ticket fare, as a whole (first graph) and separated for male and female passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5=sns.FacetGrid(df_full,hue='Survived',aspect=4)\n",
    "fig5.map(sns.kdeplot,'Pclass',shade=True)#.set(yscale = 'log')\n",
    "fig5.set(xlim=(0,df_full[\"Pclass\"].max()))\n",
    "fig5.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3=sns.FacetGrid(df_full,hue='Survived',aspect=4,row='Sex')\n",
    "fig3.map(sns.kdeplot,'Fare',shade=True)#.set(yscale = 'log')\n",
    "fig3.set(xlim=(0,df_full[\"Fare\"].max()))\n",
    "fig3.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_full[df_full.Pclass==1]\n",
    "sns.distplot(df['Fare'],  kde=False, label='First class')\n",
    "df=df_full[df_full.Pclass==2]\n",
    "sns.distplot(df['Fare'],  kde=False, label='Second class')\n",
    "df=df_full[df_full.Pclass==3]\n",
    "sns.distplot(df['Fare'],  kde=False, label='Third class')\n",
    "# Plot formatting\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.title('Fare distribution per class')\n",
    "plt.xlabel('Fare (£)')\n",
    "plt.ylabel('Frecuency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also study how the survival probability correlates with having family members aboard the titanic. The survival distribution as a function of the variable Sibsp is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5=sns.FacetGrid(df_full,hue='Survived',aspect=4)\n",
    "fig5.map(sns.kdeplot,'SibSp',shade=True)#.set(yscale = 'log')\n",
    "fig5.set(xlim=(0,df_full[\"SibSp\"].max()))\n",
    "fig5.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show that the cost of the fare may be correlated with survival, as the non-survival probability is much higher in the low-paying fares than in the more expensive ones, for both male and female passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Port of Embark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig9=sns.barplot(x=\"Embarked\",y=\"Survived\",data=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now a lot of information to start working on the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert some of the categorical variables in order to feed them to our model. First, we will convert the variable 'Sex'. Since in the records from that era the sex was treated as a binary dichotomic value (you were either male or female) we will use that in our model as well, with 1 being male and 0 female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Sex'] = df_full['Sex'].map({'male':1,'female':0})\n",
    "df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Title'] = df_full['Name'].apply(get_title)\n",
    "\n",
    "df_full['Title'] = df_full['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                            'Major', 'Rev', 'Sir', 'Jonkheer'], 'Noble')   \n",
    "df_full['Title'] = df_full['Title'].replace('Don', 'Mr')\n",
    "df_full['Title'] = df_full['Title'].replace(['Mlle','Ms'], 'Miss')\n",
    "df_full['Title'] = df_full['Title'].replace(['Mme','Dona'], 'Mrs')\n",
    "\n",
    "male_dr_filter = (df_full.Title == 'Dr') & (df_full.Sex == 1)\n",
    "female_dr_filter = (df_full.Title == 'Dr') & (df_full.Sex == 0)\n",
    "\n",
    "df_full.loc[male_dr_filter, ['Title']] = 'Mr'\n",
    "df_full.loc[female_dr_filter, ['Title']] = 'Mrs'\n",
    "\n",
    "print(pd.crosstab(df_full['Title'], df_full['Sex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation of age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_age = pd.DataFrame({'Age': df_full.Age, 'Survived': df_full.Survived}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_age = preprocessing.StandardScaler().fit_transform(X_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_age=pd.DataFrame()\n",
    "#X_age=df_full.loc[:891,['Age','Survived']].copy()\n",
    "#X_age['Survived']=df_full[:891].Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans #K Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_squared_distances = []\n",
    "K = range(1,16)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k,init='k-means++')\n",
    "    km = km.fit(X_age)\n",
    "    Sum_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, Sum_squared_distances, 'bx-')\n",
    "plt.xlabel('Number of clusters, k')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Elbow Method for optimal number of clusters')\n",
    "plt.savefig('elbow.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cl = 4\n",
    "kmeans = KMeans(n_clusters=n_cl, init='k-means++')\n",
    "kmeans.fit(X_age)\n",
    "\n",
    "X_age['Label']=kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "# See http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html\n",
    "plt.figure(figsize=(10,5))\n",
    "h = 0.01\n",
    "x_min, x_max = X_age['Age'].min() - h, X_age['Age'].max() + h\n",
    "y_min, y_max = X_age['Survived'].min() - h, X_age['Survived'].max() + h\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict the age cluster for each point in a mesh\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "cmap = sns.cubehelix_palette(start=2.8, rot=.1, as_cmap=True)\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=cmap, aspect='auto')\n",
    "\n",
    "# Plot the ages\n",
    "sns.scatterplot(x='Age', y='Survived', hue='Label', data=X_age, palette=cmap)\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w')\n",
    "plt.yticks([0, 1])\n",
    "plt.title(\"Age clusters and decision boundaries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert K-means clusters to age bands\n",
    "age_bands = []\n",
    "for k in range(n_cl):\n",
    "    age_bands.append(xx[Z==k].min())\n",
    "\n",
    "# Since the clusters are not sorted we sort the intervals\n",
    "age_bands.sort()\n",
    "\n",
    "# Set the lower bound of the first interval to 0\n",
    "age_bands[0] = 0\n",
    "\n",
    "# Set the higher bound of the last interval to infinite just in case there are older older passengers in the test set\n",
    "age_bands.append(np.inf)\n",
    "\n",
    "# Convert list to numpy array\n",
    "print(\"Age bands: {}\".format(np.array(age_bands)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fill the missing values in some of the variables. The age seems to be missing in some of the entries. To fill the data, we will calculate the median as a function of sex and passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages_table=df_full[:891].groupby(['Title','Pclass'])['Age'].median()\n",
    "ages_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Age']=df_full['Age'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.loc[(df_full.Age == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,row in df_full[df_full['Age']==0].iterrows():\n",
    "    df_full.loc[ind,'Age']=ages_table[row.Title][row.Pclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.loc[(df_full.Age == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['AgeBand'] = pd.cut(df_full['Age'], age_bands)\n",
    "\n",
    "df_full.groupby('AgeBand')['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.AgeBand.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['FamilySize'] = df_full['SibSp'] + df_full['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_full['IsAlone'] = df_full.FamilySize.apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['TicketOcurr'] = df_full.groupby('Ticket')['Ticket'].transform('size')\n",
    "df_full['FarePerPerson'] = df_full['Fare']/df_full['TicketOcurr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full[['FarePerPerson']].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fares_table=df_full[:891].groupby('Pclass')['FarePerPerson'].median()\n",
    "print(fares_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['IsAlone'] = df_full.TicketOcurr.apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full[['Fare']].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, fare in zip([df_full],[fares_table]):\n",
    "    for cls in np.unique(df.Pclass):\n",
    "        df.loc[(df['FarePerPerson'].isnull()) & (df['Pclass']==cls),'FarePerPerson']=fare.loc[cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full.FarePerPerson.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_full[df_full.Pclass==1]\n",
    "sns.distplot(df['FarePerPerson'],  kde=False, label='First class')\n",
    "df=df_full[df_full.Pclass==2]\n",
    "sns.distplot(df['FarePerPerson'],  kde=False, label='Second class')\n",
    "df=df_full[df_full.Pclass==3]\n",
    "sns.distplot(df['FarePerPerson'],  kde=False, label='Third class')\n",
    "# Plot formatting\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.title('Fare distribution per class')\n",
    "plt.xlabel('Fare per person (£)')\n",
    "plt.ylabel('Frecuency')\n",
    "plt.savefig('Fares.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full['Fare']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Port of Embarkment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full[['Embarked']].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nan=df_full[df_full[['Embarked']].isnull().any(axis=1)].index\n",
    "port_samp=list(df_train['Embarked'].sample(len(num_nan),replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(num_nan)):\n",
    "    df_full.loc[num_nan[i],'Embarked']=port_samp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full[['Embarked']].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full=pd.get_dummies(df_full, columns=[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making dummies of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full=pd.get_dummies(df_full, columns=[\"Pclass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full=pd.get_dummies(df_full, columns=[\"Title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full=pd.get_dummies(df_full, columns=[\"AgeBand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the correlation matrix for the train set\n",
    "corr_full=df_full.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_10=plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr_full, annot=True)\n",
    "plt.title(\"Titanic survivor correlation matrix heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = Sex\tIsAlone\tFarePerPersonEmbarked_CEmbarked_QEmbarked_SPclass_1Pclass_2Pclass_3Title_MasterTitle_MissTitle_MrTitle_MrsTitle_NobleAgeBand_(0.0, 13.16]AgeBand_(13.16, 27.67]AgeBand_(27.67, 43.52]AgeBand_(43.52, inf]\n",
    "data = df_full.drop(['Survived','Name','Age','SibSp','Parch','Ticket','Fare','Cabin','FamilySize','TicketOcurr','FarePerPerson'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train.Survived # being df_train the original train data we imported in the beginning \n",
    "train = data[0:891]        # \"original\" train set containing transformed/selected features\n",
    "test = data[891:]    # \"original\" test set containing transformed/selected features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.StandardScaler().fit_transform(train)\n",
    "y = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rbf = svm.SVC(kernel='rbf')\n",
    "clf_rbf.fit(X_train, y_train) \n",
    "yhat = clf_rbf.predict(X_test)\n",
    "mat=confusion_matrix(y_test, yhat)\n",
    "sns.heatmap(mat.T, cmap=(\"Blues\"), square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Not survived','Survived'],\n",
    "            yticklabels=['Not survived','Survived'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True or false indicated if the classifier predicted the class correctly. Positive or negative indicates if the classifier predicted the desired class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve , ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "title = r\"Learning Curves (SVM, RBF kernel)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "plot_learning_curve(clf_rbf, title, X, y, ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Tuned SCV Accuracy: {round(accuracy_score(y_test, yhat), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=validation\n",
    "X_val=preprocessing.StandardScaler().fit(train).transform(X_val)\n",
    "y_val=clf_rbf.predict(X_val)\n",
    "\n",
    "#print(f'Tuned SCV Accuracy: {round(accuracy_score(y_test, y_val), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "       \"PassengerId\": df_test[\"PassengerId\"],\n",
    "       \"Survived\": y_val\n",
    "   })\n",
    "\n",
    "print(submission.shape)\n",
    "submission.to_csv('titanic_svc.csv', index=False)\n",
    "\n",
    "#kaggle competitions submit -c titanic -f titanic_svc_test.csv -m \"Test of automatic submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_val=[0.01, 0.05, 0.1, 0.5, 1, 10]\n",
    "\n",
    "param_grid = [\n",
    "    {'kernel': ['linear'], 'C': C_val},\n",
    "    {'kernel': ['poly'], 'C': C_val, 'degree': [2, 3, 4, 5], 'gamma': ['scale', 'auto']},\n",
    "    {'kernel': ['rbf'], 'C': C_val, 'gamma': ['scale', 'auto']},\n",
    "    {'kernel': ['sigmoid'], 'C': C_val, 'gamma': ['scale', 'auto']}\n",
    "    ]\n",
    "\n",
    "#param_grid = [\n",
    "#    {'kernel': ['poly'], 'C': [0.05, 0.1, 0.5, 1, 5], 'degree': [2, 3, 4]},\n",
    "#    {'kernel': ['rbf'], 'C': [0.05, 0.1, 0.5, 1, 5]},\n",
    "#    {'kernel': ['sigmoid'], 'C': [0.05, 0.1, 0.5, 1, 5]}\n",
    "#    ]\n",
    "\n",
    "#param_grid = [{'kernel': ['rbf'], 'C': [0.1, 0.5]}\n",
    "#             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "clf_svc_grid = GridSearchCV(svc, param_grid, cv=5)\n",
    "best_model = clf_svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Print the value of best Hyperparameters\n",
    "print('Best kernel:', best_model.best_estimator_.get_params()['kernel'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best degree:', best_model.best_estimator_.get_params()['degree'])\n",
    "print('Best gamma:', best_model.best_estimator_.get_params()['gamma'])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = r\"Learning Curves (SVM, RBF kernel)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "plot_learning_curve(best_model, title, X, y, ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "## df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "## print(df)\n",
    "## print('\\n')\n",
    "print(f'Tuned SCV Accuracy: {round(accuracy_score(y_test, y_pred), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'criterion': ['gini'], 'n_estimators': [100], 'max_depth': list(np.arange(5,11)) + [None], \n",
    "     'min_samples_split': np.arange(2, 6), 'min_samples_leaf': np.arange(1, 6),\n",
    "     'max_features': ['sqrt', 'log2', None], 'random_state': [4]},\n",
    "    {'criterion': ['entropy'], 'n_estimators': [100], 'max_depth': list(np.arange(5,11)) + [None], \n",
    "     'min_samples_split': np.arange(2, 6), 'min_samples_leaf': np.arange(1, 6),\n",
    "     'max_features': ['sqrt', 'log2', None], 'random_state': [4]}\n",
    "    ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "clf_rf_grid = GridSearchCV(rf, param_grid, cv=5)\n",
    "best_model = clf_rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Criterion:', best_model.best_estimator_.get_params()['criterion'])\n",
    "print('Number of estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Max depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Min samples split:', best_model.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Min samples leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Max features:', best_model.best_estimator_.get_params()['max_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Random Forest Accuracy: {round(accuracy, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = validation\n",
    "X_val=preprocessing.StandardScaler().fit(train).transform(X_val)\n",
    "y_val=best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "       \"PassengerId\": df_test[\"PassengerId\"],\n",
    "       \"Survived\": y_val\n",
    "   })\n",
    "submission.to_csv('titanic_RF_best.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_best_hand = RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=None, min_samples_split=4, \n",
    "                                 #min_samples_leaf=3, max_features=None, random_state=4)\n",
    "\n",
    "title = r\"Random Forest Classifier\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "plot_learning_curve(best_model, title, X, y, ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=-1)\n",
    "#plot_learning_curve(rf_best_hand, title, X, y, ylim=(0.7, 1.01),\n",
    "#                    cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "- Hacer seleccion de algoritmos (sin XGBoost)\n",
    "- Optimizar esos algoritmos\n",
    "- Usar esos algoritmos para dar predicciones\n",
    "- Feed predicciones a XGBoost (stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 2 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(n_splits= NFOLDS, shuffle= True, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n",
    "# Class to extend XGboost classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,)) #array vacio de longitud igual al numero de el de train en dataset\n",
    "    oof_test = np.zeros((ntest,)) #lo mismo con el test\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest)) #tantas filas como KFolds y columnas igual a elemetos de test en dataset\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf): #i es el iterable de kfolds, train index y test index los valores que kfolds asigna a los elementos del train set\n",
    "        x_tr = x_train[train_index] #train del train set (crossvalidation)\n",
    "        y_tr = y_train[train_index] #etiquetas del train cross validation\n",
    "        x_te = x_train[test_index] # test del train set (crossvalidation)\n",
    "\n",
    "        clf.train(x_tr, y_tr) #entrena modelo con train cv\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te) #predice valores de test crossvalidation\n",
    "        oof_test_skf[i, :] = clf.predict(x_test) #valores predichos del testset de verdad\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0) #media en columnas de la prediccion de todos los entrenamientos del modelo con kfolds\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1) #devuelve los valores de test crossvalidation y del test de verdad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules for training and evaluation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data preprocessing and splitting\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(train)\n",
    "y = target\n",
    "\n",
    "#Number of K folds\n",
    "n_kfolds=10\n",
    "\n",
    "# Number of estimators for tree-based ensembles\n",
    "num_estimators = 100\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "#print ('Train set:', X_train.shape,  y_train.shape)\n",
    "#print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "# Calculating score for a bunch of algortihms\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n",
    "rand_state=SEED\n",
    "\n",
    "models = [LogisticRegression(\n",
    "             random_state=rand_state),\n",
    "          Perceptron(\n",
    "              random_state=rand_state), \n",
    "          SGDClassifier(\n",
    "              random_state=rand_state), \n",
    "          SVC(\n",
    "              random_state=rand_state), \n",
    "          KNeighborsClassifier(\n",
    "              ), \n",
    "          GaussianNB(\n",
    "              ),\n",
    "          DecisionTreeClassifier(\n",
    "              random_state=rand_state), \n",
    "          RandomForestClassifier(\n",
    "              random_state=rand_state,\n",
    "              n_estimators=num_estimators),\n",
    "          ExtraTreesClassifier(\n",
    "              random_state=rand_state,\n",
    "              n_estimators=num_estimators),\n",
    "          AdaBoostClassifier(\n",
    "              random_state=rand_state,\n",
    "              n_estimators=num_estimators),\n",
    "          GradientBoostingClassifier(\n",
    "              random_state=rand_state, \n",
    "              n_estimators=num_estimators)\n",
    "         ]\n",
    "\n",
    "model_name = []\n",
    "acc_test = []\n",
    "acc_train = []\n",
    "cv_scores = []\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_name.append(model.__class__.__name__)\n",
    "    acc_test.append(model.score(X_test, y_test))\n",
    "    acc_train.append(model.score(X_train, y_train))\n",
    "    cv_scores.append(cross_val_score(model, X, y, cv=5))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': model_name,\n",
    "    'CvScore' : cv_scores,\n",
    "    'TestScore': acc_test,\n",
    "    'TrainScore': acc_train\n",
    "    })\n",
    "\n",
    "\n",
    "results.insert(1, 'CVMeanScore', np.mean(results['CvScore'].tolist(), axis=1))\n",
    "results.drop(['CvScore'],axis=1,inplace=True)\n",
    "\n",
    "#by='TestScore'\n",
    "results.sort_values(by='CVMeanScore', ascending=False, ignore_index=True, inplace=True)\n",
    "#print(results)\n",
    "\n",
    "print('The five best ML models for this problem are:\\n') \n",
    "print(results.iloc[:5,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
